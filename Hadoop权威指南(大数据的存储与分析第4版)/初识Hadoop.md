# 1.1数据！数据！

现如今的数据量非常庞大，它的增长速度也日益加速，不管是个人数据还是机器产生的数据，对数据处理之后都会产生惊喜的结果

**大数据剩余好算法**，基于小数据量好的算法处理的结果不如基于大数据而使用普通算法产生的结果。

# 1.2 数据的存储与分析
现在，我们遇到了这样的问题：在磁盘容量增加的同时，磁盘的读取速度却没有与时俱进。读完一个1T的硬盘至少需要两个半小时，更别提写的速度了。我们可以通过将1T的硬盘数据分散到100个等分的硬盘中，并行读取，这样的话同样的数据只需要不到两分钟就可以读取完。

看起来很简单，但实际上我们还有一些问题需要考虑：
1. 硬件故障；在磁盘读取的过程中，很有可能其中一个硬盘发生故障，这时我们可以通过复制数据解决问题。冗余磁盘矩阵(RAID)就是基于这一原理，Hadoop的文件系统(HDFS)也是，不过它采取的方式略有不同。

2. 某些问题的数据需要各个硬盘结合起来处理数据。各种分布式系统允许结合不同数据来源的数据，但是正确性却是一个很大的挑战。MapReduce提出了一个编程模型，它抽象出一个磁盘读取的问题并将其看做是一个数据集(聚集各个硬盘的数据抽象为一个数据集，这个数据集由Key-Value组成)，这样计算由Map和Reduce组成，而且对外只提供这两部门的接口。

可以看出，针对这些问题，Hadoop为我们提供了一个可靠的且可扩展的存储和分析平台

# 1.3 查询所有数据

MapReduce看似使用了一种蛮力的方式去处理数据，它将所有的数据汇聚的一个数据集，所以在每次查询时需要查询所有数据或大部分数据。但反过来像，这也是它的能力，它是一个批量查询处理器，能够在合理的时间内处理针对整个数据集的动态查询，它通过将数据读取抽象，改变了我们只存取磁盘数据的传统看法。通过将数据整合在一起我们可以对这些数据做更多的事情。

# 1.4 不仅仅是批处理

从MapReduce的所有长处来看，它基本上是一个批处理系统，不适合进行交互式分析(离线分析工具)。

现在Hadoop的发展已经超越了批处理本身。实际上，名词Hadoop指的是一个更大的多个项目组成的生态系统，而不仅仅是HDFS和MapRedece。

第一个提供在线访问访问的组件是HBase，它使用HDFS作为底层存储模型。它提供对单行数据或者整个数据块的读写批操作。

在Hadoop 2中出现的YARN则是一个集群资源管理系统，它允许任何一个分布式程序(不仅是MapReduce)基于Hadoop集群的数据而运行。

还有一些其他的与Hadoop协同工作的处理模式：

* Interactive SQL (交互式SQL)
* Iterative processing (迭代处理)
* Stream processing (流处理)
* Search (搜索)

无论Hadoop上出现多少处理框架，就批处理而言，MapReduce仍然占有一席之地，它提出的一些概念具有通用性，因此，MapReduce的工作机制值得我们去了解