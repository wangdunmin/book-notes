# 1.1数据！数据！

现如今的数据量非常庞大，它的增长速度也日益加速，不管是个人数据还是机器产生的数据，对数据处理之后都会产生惊喜的结果

**大数据剩余好算法**，基于小数据量好的算法处理的结果不如基于大数据而使用普通算法产生的结果。

# 1.2 数据的存储与分析
现在，我们遇到了这样的问题：在磁盘容量增加的同时，磁盘的读取速度却没有与时俱进。读完一个1T的硬盘至少需要两个半小时，更别提写的速度了。我们可以通过将1T的硬盘数据分散到100个等分的硬盘中，并行读取，这样的话同样的数据只需要不到两分钟就可以读取完。

看起来很简单，但实际上我们还有一些问题需要考虑：
1. 硬件故障；在磁盘读取的过程中，很有可能其中一个硬盘发生故障，这时我们可以通过复制数据解决问题。冗余磁盘矩阵(RAID)就是基于这一原理，Hadoop的文件系统(HDFS)也是，不过它采取的方式略有不同。

2. 某些问题的数据需要各个硬盘结合起来处理数据。各种分布式系统允许结合不同数据来源的数据，但是正确性却是一个很大的挑战。MapReduce提出了一个编程模型，它抽象出一个磁盘读取的问题并将其看做是一个数据集(聚集各个硬盘的数据抽象为一个数据集，这个数据集由Key-Value组成)，这样计算由Map和Reduce组成，而且对外只提供这两部门的接口。

可以看出，针对这些问题，Hadoop为我们提供了一个可靠的且可扩展的存储和分析平台

# 1.3 查询所有数据

MapReduce看似使用了一种蛮力的方式去处理数据，它将所有的数据汇聚的一个数据集，所以在每次查询时需要查询所有数据或大部分数据。但反过来像，这也是它的能力，它是一个批量查询处理器，能够在合理的时间内处理针对整个数据集的动态查询，它通过将数据读取抽象，改变了我们只存取磁盘数据的传统看法。通过将数据整合在一起我们可以对这些数据做更多的事情。

# 1.4 不仅仅是批处理

从MapReduce的所有长处来看，它基本上是一个批处理系统，不适合进行交互式分析(离线分析工具)。

现在Hadoop的发展已经超越了批处理本身。实际上，名词Hadoop指的是一个更大的多个项目组成的生态系统，而不仅仅是HDFS和MapRedece。

第一个提供在线访问访问的组件是HBase，它使用HDFS作为底层存储模型。它提供对单行数据或者整个数据块的读写批操作。

在Hadoop 2中出现的YARN则是一个集群资源管理系统，它允许任何一个分布式程序(不仅是MapReduce)基于Hadoop集群的数据而运行。

还有一些其他的与Hadoop协同工作的处理模式：

* Interactive SQL (交互式SQL)
* Iterative processing (迭代处理)
* Stream processing (流处理)
* Search (搜索)

无论Hadoop上出现多少处理框架，就批处理而言，MapReduce仍然占有一席之地，它提出的一些概念具有通用性，因此，MapReduce的工作机制值得我们去了解

# 1.5 相较于其他系统的优势

Hadoop不是历史上第一个用于数据存储和分析的分布式系统

## 1.5.1 关系型数据库管理系统

硬盘寻址时间的提升远远不如传输速率的提升；关系型数据库的读写采用寻址的方式，所以关系型数据库读取大量数据集时会花费更长的时间；如果它只是更新一小部分数据，那么数据库(B树)的效率更高，但是要是更新大量数据时，数据库(B树)的效率明显落后MapReduce，因为他需要"排序/合并(sort/merge)"来重建数据库。

以下是关系型数据库与MapReduce的比较，我们可以依照下面的特性去选择使用数据库还是MapReduce
||关系型数据库|MapReduce|
|---|---|---|
|数据大小|GB|PB|
|数据存取|交互式和批处理|批处理|
|更新|多次读/写|一次写入，多次读取|
|事务|ACID|无|
|结构|写时模式|读时模式|
|完整性|高|低|
|横向扩展|非线性的|线性的|

关系型数据库和Hadoop之间的区别越来越模糊，其一，关系型数据库正在吸收Hadoop的一些思想；其二，像Hive这样的Hadoop系统不仅变得更具有交互性，还增加了索引，事务这样的特性。

还有一个区别是他们操作数据的结构化程度，数据依照结构化分为三种：
1. 结构化数据：有既定格式的数据
2. 半结构化数据：有格式，但是只是对数据做一般性指导，格式经常会被忽略
3. 非结构化数据：没有内部结构

Hadoop对后两种数据非常有效，因为他是在处理数据时才对数据进行解释(**读时模式**)

MapReduce(以及Hadoop中其他的处理模式)可以随数据规模线性伸缩。

## 1.5.2 网格计算

高性能计算(High Performance Computing，HPC)和网格计算(Grid Computing)组织多年来一直在研究大规模数据处理，主要使用类似于消息传递接口(Message  Passing Interface, MPI)的API。广义上讲：高性能计算采用的方法是将作业分散到集群的各台机器上，这些机器访问存储区域网络(SAN)所组成的共享文件系统。这比较适合计算密集型的作业，如果数据量更庞大的话，那么就会因为网络带宽的问题而闲下来等待数据。

Hadoop尽可能在计算节点上存储数据，趋势线数据的本地快速访问。实现数据本地化后，Hasoop通过显示网络拓扑结构来保留网络带宽。实现数据的快速访问同时，他还保留了计算密集型数据分析的能力

相较于MPI，Hadoop在更高的抽象层次去处理数据，减少了编程的难度

## 1.5.3 志愿计算

志愿计算是指：志愿者把自己计算机CPU的空闲时间贡献出来去计算某些计算项目的数据。计算项目会把问题分成很多个**工作单元**，发到各地的计算机上进行分析。由于数据传输到世界各地需要时间，所以它适合计算CPU高度密集的数据

MapReduce的三大设计目标：
1. 为只需短短几分钟或几小时就可以完成的作业提供服务
2. 运行与同一个内部有高速网络连接的数据中心内
3. 数据中心内的计算机是可靠的，专业的硬件

# 1.6 Apache Hadoop的发展简史

Hadoop创始人道格卡丁，它是同样也是Lucene，Nutch等项目的发起人。Nutch诞生于Lucene。

2002年Nutch项目开始

2003年受到GFS(谷歌分布式文件系统)启发，2004年实现了Nutch分布式文件系统(NDFS)

2004年手到谷歌的MapReduce系统的启发，2005年初在Nutch中实现了自己的MapReduce系统

2006年，开大人员将NDFS和MapReduce模块移出Nutch形成Lucene的一个子项目，命名为**Hadoop**，随后它在雅虎中使用

2008年2月，雅虎宣布它的搜索引擎所使用的索引是在一个拥有一万个内核的Hadoop集群上创建。

2008年1月，Hadoop成为Apache的顶级项目

2008年4月，Hadoop成为最快的TB级数据排序系统

目前，Hadoop被主流企业广泛使用


